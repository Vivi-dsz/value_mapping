{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b1334f",
   "metadata": {},
   "source": [
    "## Sample \"About Me\" Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4263c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_text ={\"Klrana\" : \"\"\"\n",
    "Hej, we’re Klarna\n",
    "We’re here to set the new standard for how people shop and pay–proudly Swedish.\n",
    "\n",
    "Smarter shopping starts here\n",
    "At Klarna, we're redefining the shopping experience to help people get more out of their money. Here's how:\n",
    "Pay your way: Choose from interest-free payment plans and customizable payment options.\n",
    "Earn while you shop: Receive cashback directly in your Klarna balance.\n",
    "Secure shopping: Keep your data safe using advanced encryption and 24/7 fraud monitoring.\n",
    "Our History\n",
    "Made in Stockholm\n",
    "Three young Swedish entrepreneurs had a brilliant idea back in 2005—but not the best name. Kreditor became Klarna in 2010.\n",
    "Unicorn status unlocked\n",
    "In 2012, Klarna reached a significant milestone with a $1B+ valuation, recognizing our rapid growth and market impacts.\n",
    "Klarna's family grows\n",
    "In 2014, Klarna acquired SOFORT, creating Europe’s fastest-growing online payments group.\n",
    "A bold new era\n",
    "In 2017, Klarna transformed from blue to bold pink, and secured a full banking license, expanding our capabilities to serve customers.\n",
    "The Klarna app arrives\n",
    "Launched in 2018, the Klarna app provides users with tools for smarter shopping, budget management, and seamless payments across online and in-store experiences.\n",
    "The smart spending leader\n",
    "As of 2025, Klarna is a leader in digital payments, offering flexible payment options, cashback, and financial tools to millions of shoppers worldwide.\n",
    "\n",
    "The numbers don't lie\n",
    "100m\n",
    "active consumers\n",
    "\n",
    "720k\n",
    "M erchants\n",
    "\n",
    "2.9m\n",
    "transactions per day\n",
    "\n",
    "26\n",
    "C ountries supported\n",
    "\n",
    "Trusted by the world's most loved brands\n",
    "\n",
    "Meet the board\n",
    "The board is Klarna’s top decision-making body, overseeing strategy, operations, and corporate governance to ensure accountability to both the organization and investors.\n",
    "\n",
    "Get to know our culture\n",
    "With offices around the world, our global team blends start-up energy with a drive to create bold, impactful change and redefine smarter spending.\n",
    "\"\"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7060d4",
   "metadata": {},
   "source": [
    "## Questions ##\n",
    "\n",
    "1. What we do with typos? Like C ountries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eba642",
   "metadata": {},
   "source": [
    "## Sample \"Review\" Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b67f649",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd86b86c",
   "metadata": {},
   "source": [
    "## Keywork Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463e277",
   "metadata": {},
   "source": [
    "\n",
    "def get_daily_sentiment(\n",
    "    api_key: str,\n",
    "    query_keyword: str,\n",
    "    start_date: Union[str, datetime],\n",
    "    end_date: Union[str, datetime],\n",
    "    verbose: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches daily sentiment scores for a given keyword based on news headlines.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): NewsAPI API key.\n",
    "        query_keyword (str): Search term for news (e.g., \"Apple\", \"bond market\").\n",
    "        start_date (str or datetime): Start date (inclusive). Format: \"YYYY-MM-DD\" or datetime.\n",
    "        end_date (str or datetime): End date (inclusive). Format: \"YYYY-MM-DD\" or datetime.\n",
    "        verbose (bool): Print progress for each day.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Daily sentiment with:\n",
    "            - 'date' (datetime.date)\n",
    "            - 'sent_pos' (float): Proportion of positive headlines\n",
    "            - 'sent_neg' (float): Proportion of negative headlines\n",
    "            - 'sent_neu' (float): Proportion of neutral headlines\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    current = start_date\n",
    "    result = []\n",
    "\n",
    "    while current <= end_date:\n",
    "        from_date = current.strftime(\"%Y-%m-%d\")\n",
    "        to_date = (current + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        headlines = []  # ensure it's defined before the try block\n",
    "\n",
    "        try:\n",
    "            headlines = get_news_headlines(api_key, query_keyword, from_date, to_date)\n",
    "            if verbose:\n",
    "                print(f\"{query_keyword} on {from_date}: {len(headlines)} headlines\")\n",
    "            sent = get_sentiment_breakdown(headlines)\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {from_date}: {e}\")\n",
    "            sent = {'sent_pos': 0, 'sent_neg': 0, 'sent_neu': 1}  # default to neutral\n",
    "\n",
    "        result.append({\n",
    "            \"date\": current.date(),\n",
    "            \"sent_pos\": sent['sent_pos'],\n",
    "            \"sent_neg\": sent['sent_neg'],\n",
    "            \"sent_neu\": sent['sent_neu'],\n",
    "        })\n",
    "\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95274afd",
   "metadata": {},
   "source": [
    "dfs = []\n",
    "\n",
    "for keyword in general_news_keywords:\n",
    "    df = get_daily_sentiment(\n",
    "        api_key=API_KEY,\n",
    "        query_keyword=keyword,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        verbose=False\n",
    "    )\n",
    "    df['keyword'] = keyword\n",
    "    dfs.append(df)\n",
    "\n",
    "df_genral_news = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3cc15a",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def clean_and_tokenize(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean Brand's 'About Us' text.\n",
    "    Cleans the input text and returns both:\n",
    "    - cleaned text (str)\n",
    "    - tokenized list of words (List[str])\n",
    "    \"\"\"\n",
    "    # Normalize unicode dashes, quotes, etc.\n",
    "    # Fixes weird characters (like curly quotes → straight quotes, long dashes → `-`)\n",
    "    text = unicodedata.normalize(\"NFKC\", raw_text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove weird line breaks and extra spacing\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)      # Multiple blank lines into single ones (removes visual spacing)\n",
    "    text = re.sub(r'[ \\t]{2,}', ' ', text)    # Multiple spaces/tabs into just one (normalization)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)   # Removes special charachters, keeps only alphabet, digit, and spaces\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    tockenized_text = word_tokenize(text)\n",
    "\n",
    "    return tockenized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rows = []\n",
    "for brand, raw_text in brand_text.items():\n",
    "    tokens = clean_and_tokenize(raw_text)\n",
    "    rows.append({\n",
    "        \"brand\": brand,\n",
    "        \"tokens\": tokens\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4995ca",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddb10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment pipeline\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
